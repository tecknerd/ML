{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PINNs.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from re import VERBOSE\n","# This line is very important on Colab. \n","# Without it, Tensorflow 2.x will run and PINNs will not work.\n","%tensorflow_version 1.x\n","\n","%xmode VERBOSE\n","# %pdb on\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"YCYoaXw2pCDG"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5ti6xPK9wziv"},"outputs":[],"source":["import sys\n","\n","# !pip install ipdb\n","# import ipdb\n","sys.path.insert(0, '../../Utilities/')\n","\n","import math\n","import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import scipy.io\n","from scipy.interpolate import griddata\n","from mpl_toolkits.axes_grid1 import make_axes_locatable\n","import matplotlib.gridspec as gridspec\n","import time\n","\n","print(tf.test.gpu_device_name())\n","\n","\n","using_gpu = tf.test.is_gpu_available(\n","  cuda_only=False, min_cuda_compute_capability=None\n",")\n","\n","print(using_gpu)\n","\n","if using_gpu:\n","  gpu_info = !nvidia-smi\n","  gpu_info = '\\n'.join(gpu_info)\n","  \n","  if gpu_info.find('failed') >= 0:\n","    print('Not connected to a GPU')\n","  else:\n","    print(gpu_info)\n"]},{"cell_type":"code","source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"],"metadata":{"id":"swqaW788faB5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.random.seed(1234)\n","#tf.set_random_seed(1234)\n","\n","class PhysicsInformedNN:\n","    # Initialize the class\n","    def __init__(self, X, u, layers, lb, ub):\n","        \n","        self.lb = lb\n","        self.ub = ub\n","        \n","        self.x = X[:,0:1]\n","        self.y = X[:,1:2]\n","        self.t = X[:,2:3]\n","        self.u = u\n","        \n","        self.layers = layers\n","        \n","        # Initialize NNs\n","        self.weights, self.biases = self.initialize_NN(layers)\n","        \n","        # tf placeholders and graph\n","        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n","       #self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n","                                                     #log_device_placement=True))\n","        \n","        # Initialize parameters\n","        self.alpha_1 = tf.Variable([-1.8], dtype=tf.float32)\n","        \n","        self.x_tf = tf.placeholder(tf.float32, shape=[None, self.x.shape[1]])\n","        self.y_tf = tf.placeholder(tf.float32, shape=[None, self.y.shape[1]])\n","        self.t_tf = tf.placeholder(tf.float32, shape=[None, self.t.shape[1]])\n","        self.u_tf = tf.placeholder(tf.float32, shape=[None, self.u.shape[1]])\n","                \n","        self.u_pred = self.net_u(self.x_tf,self.y_tf, self.t_tf)\n","        self.f_pred = self.net_f(self.x_tf,self.y_tf, self.t_tf)\n","        \n","        self.loss = tf.reduce_mean(tf.square(self.u_tf - self.u_pred)) + \\\n","                    tf.reduce_mean(tf.square(self.f_pred))\n","        \n","        self.optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.loss, \n","                                                                method = 'L-BFGS-B', \n","                                                                options = {'maxiter': 50000,\n","                                                                           'maxfun': 50000,\n","                                                                           'maxcor': 50,\n","                                                                           'maxls': 50,\n","                                                                           'ftol' : 1.0 * np.finfo(float).eps})\n","        \n","        self.loss_writer = open('/content/drive/MyDrive/Colab Notebooks/Colab/PINN_loss.txt', 'w')\n","\n","        # self.optimizer_Adam = tf.train.AdamOptimizer(learning_rate=0.001, beta1=0.2, beta2=0.2) \n","        self.optimizer_Adam = tf.train.AdamOptimizer() \n","        self.train_op_Adam = self.optimizer_Adam.minimize(self.loss)\n","        \n","        init = tf.global_variables_initializer()\n","        self.sess.run(init)\n","\n","    def initialize_NN(self, layers):        \n","        weights = []\n","        biases = []\n","        \n","        num_layers = len(layers) \n","        for l in range(0,num_layers-1):\n","            W = self.xavier_init(size=[layers[l], layers[l+1]])\n","            b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float32), dtype=tf.float32)\n","            weights.append(W)\n","            biases.append(b)        \n","        return weights, biases\n","        \n","    def xavier_init(self, size):\n","        in_dim = size[0]\n","        out_dim = size[1]        \n","        xavier_stddev = np.sqrt(2/(in_dim + out_dim))\n","\n","        return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev), dtype=tf.float32)\n","    \n","    def neural_net(self, X, weights, biases, eps=1e-3):\n","        num_layers = len(weights) + 1\n","\n","        H = 2.0*(X - self.lb)/(self.ub - self.lb) - 1.0\n","        for l in range(0,num_layers-2):\n","          W = weights[l]\n","          b = biases[l]\n","          H_norm = tf.compat.v1.layers.batch_normalization(H)\n","          H = tf.nn.leaky_relu(tf.add(tf.matmul(H_norm, W), b))\n","        W = weights[-1]\n","        b = biases[-1]\n","        Y = tf.nn.relu(tf.add(tf.matmul(H, W), b))\n","\n","        return Y\n","            \n","    def net_u(self,x,y,t):  \n","        u = self.neural_net(tf.concat([x,y,t],1), self.weights, self.biases)\n","\n","        return u\n","    \n","    def net_f(self, x,y,t):\n","        alpha_1 = self.alpha_1        \n","        u = self.net_u(x,y,t)\n","        u_t = tf.gradients(u, t)[0]\n","        u_x = tf.gradients(u, x)[0]\n","        u_y = tf.gradients(u, y)[0]\n","        u_xx = tf.gradients(u_x, x)[0]\n","        u_yy = tf.gradients(u_y, y)[0]\n","        f = u_t - alpha_1*(u_xx + u_yy)\n","\n","        return f\n","    \n","    def callback(self, loss, alpha_1):\n","        self.loss_writer.write('Loss: %e, alpha1: %.5f' % (loss, alpha_1))\n","        print('Loss: %e, alpha1: %.5f' % (loss, alpha_1))\n","        \n","        \n","    def train(self, nIter):\n","        tf_dict = {self.x_tf: self.x, self.y_tf: self.y, self.t_tf: self.t, self.u_tf: self.u}\n","\n","        start_time = time.time()\n","        for it in range(nIter):\n","            self.sess.run(self.train_op_Adam, tf_dict)\n","            \n","            # Print            \n","            if it % 10 == 0:\n","                elapsed = time.time() - start_time\n","                loss_value = self.sess.run(self.loss, tf_dict)\n","                alpha_1_value = self.sess.run(self.alpha_1)\n","                \n","                print('It: %d, Loss: %.3e, alpha_1: %.3f, Time: %.2f' % \n","                      (it, loss_value, alpha_1_value, elapsed))\n","                \n","                self.loss_writer.write('It: %d, Loss: %.3e, alpha_1: %.3f, Time: %.2f \\n' % \n","                      (it, loss_value, alpha_1_value, elapsed))\n","                \n","                start_time = time.time()\n","        \n","        \n","        self.optimizer.minimize(self.sess,\n","                                feed_dict = tf_dict,\n","                                fetches = [self.loss, self.alpha_1],\n","                                loss_callback = self.callback)\n","        \n","        self.loss_writer.close()\n","        \n","    def predict(self, X_star):\n","        \n","        tf_dict = {self.x_tf: X_star[:,0:1],self.y_tf: X_star[:,1:2], self.t_tf: X_star[:,2:3]}\n","        \n","        u_star = self.sess.run(self.u_pred, tf_dict)\n","        f_star = self.sess.run(self.f_pred, tf_dict)\n","        \n","        return u_star, f_star"],"metadata":{"id":"oPGMZyaPzK_2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#if __name__ == \"__main__\": \n","     \n","    #nu = 0.01/np.pi\n","\n","N_u = 1000000# 853000\n","layers = [3, 20, 20, 20, 20, 20, 20, 20, 20, 1] # added last 4 hidden layers\n","    \n","input = np.load('/content/drive/MyDrive/Colab Notebooks/Colab/input.npy') # X1, X2 and T as three columns\n","output = np.load('/content/drive/MyDrive/Colab Notebooks/Colab/output.npy') # This is the solution of 2-D heat equation\n","output = output.reshape(output.shape[0],1) # changes shape from (n, ) to (n, 1)\n","    \n","X_star = input #input is coming from the 2Dheat.py file\n","u_star = output.flatten()[:,None] #output is coming from the 2Dheat.py file \n","\n","# Domain bounds\n","lb = input.min(0)\n","ub = input.max(0)\n","\n","print(lb)\n","print(ub)"],"metadata":{"id":"EJDkfU02zH1M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["start_point = 1600\n","stop_point = 1844799\n","sa = np.linspace(start_point, stop_point, stop_point-start_point)\n","# t=0 values are preseved in the original dataset as they are intial conditions\n","idx_sample = np.random.choice(sa, N_u, replace=False)\n","\n","# New train Data for 2-D Heat Equation\n","X_u_train = np.vstack((input[0:1600, :], input[idx_sample.astype(int), :]))\n","u_train = np.concatenate([output[0:1600], output[idx_sample.astype(int)]])\n","\n","print(X_u_train.min(0))\n","print(X_u_train.max(0))"],"metadata":{"id":"-O7V5e_J0f3S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["######################################################################\n","######################## Noiseless Data ##############################\n","######################################################################\n","noise = 0.0            \n","         \n","# idx = np.random.choice(input.shape[0], N_u, replace=False)\n","# X_u_train = input[idx,:]\n","# u_train = u_star[idx,:]\n","\n","# np.where(input[:,2] >= 0.09)\n","\n","start_point = 1600\n","stop_point = 1844799\n","sa = np.linspace(start_point, stop_point, stop_point-start_point)\n","# t=0 values are preseved in the original dataset as they are intial conditions\n","idx_sample = np.random.choice(sa, N_u, replace=False)\n","\n","# New train Data for 2-D Heat Equation\n","X_u_train = np.vstack((input[0:1600, :], input[idx_sample.astype(int), :]))\n","u_train = np.concatenate([output[0:1600], output[idx_sample.astype(int)]])\n","\n","model = PhysicsInformedNN(X_u_train, u_train, layers, lb, ub)\n","model.train(10000)#You can run for small iterations first, to see whether it is running properly\n","\n","u_pred, f_pred = model.predict(X_star)\n","        \n","error_u = np.linalg.norm(u_star-u_pred,2)/np.linalg.norm(u_star,2)\n","    \n","alpha_1_value = model.sess.run(model.alpha_1)\n","error_alpha_1 = np.abs(alpha_1_value - 2)*100\n","\n","print('Error u: %e' % (error_u))    \n","print('Error l1: %.5f%%' % (error_alpha_1)) \n","\n","df = open('output.txt', 'w')\n","df.write('Error u: %e' % (error_u))  \n","df.write('\\n')\n","df.close()\n","\n","np.save('/content/drive/MyDrive/Colab Notebooks/Colab//u_train-21March.npy', u_train)\n","\n","u_pred_3D = np.reshape(u_pred, (1600, 40, 40))\n","np.save('/content/drive/MyDrive/Colab Notebooks/Colab/u_pred_3D-21March.npy', u_pred_3D)"],"metadata":{"id":"yPvl7r_f0F1W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# %debug "],"metadata":{"id":"E6VMyJuTknGL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["######################################################################\n","############################ Animation ###############################\n","###################################################################### \n","\n","# Animation imports\n","from matplotlib.animation import FuncAnimation\n","import matplotlib.animation as animation\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","# plt.rc('text', usetex=True)\n","# matplotlib.rcParams['text.latex.preamble'] = [r'\\usepackage{amsmath}']\n","# !apt install texlive-fonts-recommended texlive-fonts-extra cm-super dvipng\n","!pip install ffmpeg-python \n","\n","\n","u_pred_3D = np.reshape(u_pred, (1600, 40, 40))\n","# u_pred_3D = np.load('/content/drive/MyDrive/Colab Notebooks/Colab/u_pred_3D-18March2022.npy')\n","\n","plate_length = 1  # 10\n","delta_x = 0.025\n","\n","alpha = 2\n","\n","num_x_inter = int((plate_length)/delta_x)\n","max_iter_time = num_x_inter * num_x_inter\n","\n","delta_t = (delta_x ** 2)/(4 * alpha)\n","\n","tick_intervals = np.linspace(0, 40, 11, retstep=True)[0]\n","tick_labels = np.array(\n","['0.0', '0.1', '0.2', '0.3', '0.4', '0.5', '0.6', '0.7', '0.8', '0.9', '1.0'])\n","\n","\n","def plotheatmap(u_k, k):\n","  # Clear the current plot figure\n","  plt.clf()\n","\n","  plt.title(f\"Temperature at t = {k*delta_t:.3f} unit time\")\n","\n","  plt.xlabel(\"x\")\n","  plt.xticks(tick_intervals, tick_labels)\n","\n","  plt.ylabel(\"y\")\n","  plt.yticks(tick_intervals, tick_labels)\n","\n","        # This is to plot u_k (u at time-step k)\n","  plt.pcolormesh(u_k, cmap=plt.cm.jet, vmin=0, vmax=100)\n","  plt.colorbar()\n","\n","  return plt\n","\n","\n","def animate(k):\n","  plotheatmap(u_pred_3D[k], k)\n","\n","\n","anim = animation.FuncAnimation(\n","    plt.figure(), animate, interval=1, frames=max_iter_time, repeat=False)\n","anim.save(\"/content/drive/MyDrive/Colab Notebooks/Colab/Images/predicted_heat_equation_solution-18March2022-2.gif\", codec='gif', dpi=72, fps=100)"],"metadata":{"id":"1i9X_YJ6xdrt"},"execution_count":null,"outputs":[]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PINNs.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1AlBbX1PKeAzxNYQSpJI0mR-vcu7REB3C","authorship_tag":"ABX9TyOd62GIVRPZkVfrGLkiS7qu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from re import VERBOSE\n","# This line is very important on Colab. \n","# Without it, Tensorflow 2.x will run and PINNs will not work.\n","%tensorflow_version 1.x\n","\n","%xmode VERBOSE\n","%pdb on"],"metadata":{"id":"YCYoaXw2pCDG","executionInfo":{"status":"ok","timestamp":1646529760812,"user_tz":420,"elapsed":261,"user":{"displayName":"Albert Romero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjxCAAyS0BN5ZLXCI4Yl-md_NQNECK-67_AEebWMw=s64","userId":"15395578801537283548"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b02b9fc9-b7ea-45ec-f22e-45efb116a16c"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow 1.x selected.\n","Exception reporting mode: Verbose\n","Automatic pdb calling has been turned ON\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5ti6xPK9wziv","executionInfo":{"status":"ok","timestamp":1646529768056,"user_tz":420,"elapsed":5593,"user":{"displayName":"Albert Romero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjxCAAyS0BN5ZLXCI4Yl-md_NQNECK-67_AEebWMw=s64","userId":"15395578801537283548"}},"outputId":"5d338724-aef9-43b6-bf60-7bf7b3e41fc8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: ipdb in /usr/local/lib/python3.7/dist-packages (0.13.9)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipdb) (4.4.2)\n","Requirement already satisfied: toml>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from ipdb) (0.10.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from ipdb) (57.4.0)\n","Requirement already satisfied: ipython>=7.17.0 in /usr/local/lib/python3.7/dist-packages (from ipdb) (7.32.0)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (5.1.1)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (4.8.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (0.1.3)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (2.6.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (3.0.28)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (0.18.1)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (0.7.5)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (0.2.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython>=7.17.0->ipdb) (0.8.3)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython>=7.17.0->ipdb) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.17.0->ipdb) (0.2.5)\n","/device:GPU:0\n","True\n","Sun Mar  6 01:22:47 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   44C    P0    35W / 250W |    257MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}],"source":["import sys\n","\n","!pip install ipdb\n","import ipdb\n","sys.path.insert(0, '../../Utilities/')\n","\n","import math\n","import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import scipy.io\n","from scipy.interpolate import griddata\n","# from plotting import newfig, savefig\n","from mpl_toolkits.axes_grid1 import make_axes_locatable\n","import matplotlib.gridspec as gridspec\n","import time\n","\n","# Animation imports\n","from matplotlib.animation import FuncAnimation\n","import matplotlib.animation as animation\n","import matplotlib.pyplot as plt\n","\n","print(tf.test.gpu_device_name())\n","\n","\n","using_gpu = tf.test.is_gpu_available(\n","  cuda_only=False, min_cuda_compute_capability=None\n",")\n","\n","print(using_gpu)\n","\n","if using_gpu:\n","  gpu_info = !nvidia-smi\n","  gpu_info = '\\n'.join(gpu_info)\n","  \n","  if gpu_info.find('failed') >= 0:\n","    print('Not connected to a GPU')\n","  else:\n","    print(gpu_info)\n"]},{"cell_type":"code","source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"swqaW788faB5","executionInfo":{"status":"ok","timestamp":1646529768947,"user_tz":420,"elapsed":3,"user":{"displayName":"Albert Romero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjxCAAyS0BN5ZLXCI4Yl-md_NQNECK-67_AEebWMw=s64","userId":"15395578801537283548"}},"outputId":"8ec5aa2d-ac88-4d29-de18-5f5d24cca37f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Your runtime has 27.3 gigabytes of available RAM\n","\n","You are using a high-RAM runtime!\n"]}]},{"cell_type":"code","source":["#!/usr/bin/env python3\n","# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Mon Oct  9 20:11:57 2017\n","\n","@author: mraissi\n","\"\"\"\n","\n","import numpy as np\n","import matplotlib as mpl\n","#mpl.use('pgf')\n","\n","def figsize(scale, nplots = 1):\n","    fig_width_pt = 390.0                          # Get this from LaTeX using \\the\\textwidth\n","    inches_per_pt = 1.0/72.27                       # Convert pt to inch\n","    golden_mean = (np.sqrt(5.0)-1.0)/2.0            # Aesthetic ratio (you could change this)\n","    fig_width = fig_width_pt*inches_per_pt*scale    # width in inches\n","    fig_height = nplots*fig_width*golden_mean              # height in inches\n","    fig_size = [fig_width,fig_height]\n","    return fig_size\n","\n","pgf_with_latex = {                      # setup matplotlib to use latex for output\n","    \"pgf.texsystem\": \"pdflatex\",        # change this if using xetex or lautex\n","    \"text.usetex\": True,                # use LaTeX to write all text\n","    \"font.family\": \"serif\",\n","    \"font.serif\": [],                   # blank entries should cause plots to inherit fonts from the document\n","    \"font.sans-serif\": [],\n","    \"font.monospace\": [],\n","    \"axes.labelsize\": 10,               # LaTeX default is 10pt font.\n","    \"font.size\": 10,\n","    \"legend.fontsize\": 8,               # Make the legend/label fonts a little smaller\n","    \"xtick.labelsize\": 8,\n","    \"ytick.labelsize\": 8,\n","    \"figure.figsize\": figsize(1.0),     # default fig size of 0.9 textwidth\n","    \"pgf.preamble\": [\n","        r\"\\usepackage[utf8x]{inputenc}\",    # use utf8 fonts becasue your computer can handle it :)\n","        r\"\\usepackage[T1]{fontenc}\",        # plots will be generated using this preamble\n","        ]\n","    }\n","mpl.rcParams.update(pgf_with_latex)\n","\n","import matplotlib.pyplot as plt\n","\n","# I make my own newfig and savefig functions\n","def newfig(width, nplots = 1):\n","    fig = plt.figure(figsize=figsize(width, nplots))\n","    ax = fig.add_subplot(111)\n","    return fig, ax\n","\n","def savefig(filename, crop = True):\n","    if crop == True:\n","#        plt.savefig('{}.pgf'.format(filename), bbox_inches='tight', pad_inches=0)\n","        plt.savefig('{}.pdf'.format(filename), bbox_inches='tight', pad_inches=0)\n","        plt.savefig('{}.eps'.format(filename), bbox_inches='tight', pad_inches=0)\n","    else:\n","#        plt.savefig('{}.pgf'.format(filename))\n","        plt.savefig('{}.pdf'.format(filename))\n","        plt.savefig('{}.eps'.format(filename))"],"metadata":{"id":"n-zPFcRfn-vh","executionInfo":{"status":"ok","timestamp":1646529772603,"user_tz":420,"elapsed":249,"user":{"displayName":"Albert Romero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjxCAAyS0BN5ZLXCI4Yl-md_NQNECK-67_AEebWMw=s64","userId":"15395578801537283548"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["np.random.seed(1234)\n","#tf.set_random_seed(1234)\n","\n","class PhysicsInformedNN:\n","    # Initialize the class\n","    def __init__(self, X, u, layers, lb, ub):\n","        \n","        self.lb = lb\n","        self.ub = ub\n","        \n","        self.x = X[:,0:1]\n","        self.y = X[:,1:2]\n","        self.t = X[:,2:3]\n","        self.u = u\n","        \n","        self.layers = layers\n","        \n","        # Initialize NNs\n","        self.weights, self.biases = self.initialize_NN(layers)\n","        \n","        # tf placeholders and graph\n","        self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n","       #self.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n","                                                     #log_device_placement=True))\n","        \n","        # Initialize parameters\n","        self.alpha_1 = tf.Variable([-1.8], dtype=tf.float32)\n","        #self.lambda_2 = tf.Variable([-6.0], dtype=tf.float32)\n","        \n","        self.x_tf = tf.placeholder(tf.float32, shape=[None, self.x.shape[1]])\n","        self.y_tf = tf.placeholder(tf.float32, shape=[None, self.y.shape[1]])\n","        self.t_tf = tf.placeholder(tf.float32, shape=[None, self.t.shape[1]])\n","        self.u_tf = tf.placeholder(tf.float32, shape=[None, self.u.shape[1]])\n","                \n","        self.u_pred = self.net_u(self.x_tf,self.y_tf, self.t_tf)\n","        self.f_pred = self.net_f(self.x_tf,self.y_tf, self.t_tf)\n","        \n","        self.loss = tf.reduce_mean(tf.square(self.u_tf - self.u_pred)) + \\\n","                    tf.reduce_mean(tf.square(self.f_pred))\n","        \n","        self.optimizer = tf.contrib.opt.ScipyOptimizerInterface(self.loss, \n","                                                                method = 'L-BFGS-B', \n","                                                                options = {'maxiter': 50000,\n","                                                                           'maxfun': 50000,\n","                                                                           'maxcor': 50,\n","                                                                           'maxls': 50,\n","                                                                           'ftol' : 1.0 * np.finfo(float).eps})\n","        \n","        self.optimizer_Adam = tf.train.AdamOptimizer(learning_rate=0.01) # try both a larger and smaller rate\n","        # self.optimizer_Adam = tf.train.GradientDescentOptimizer(learning_rate=0.0001)\n","        self.train_op_Adam = self.optimizer_Adam.minimize(self.loss)\n","        \n","        init = tf.global_variables_initializer()\n","        self.sess.run(init)\n","\n","    def initialize_NN(self, layers):        \n","        weights = []\n","        biases = []\n","        \n","        num_layers = len(layers) \n","        for l in range(0,num_layers-1):\n","            W = self.xavier_init(size=[layers[l], layers[l+1]])\n","            b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float32), dtype=tf.float32)\n","            weights.append(W)\n","            biases.append(b)        \n","        return weights, biases\n","        \n","    def xavier_init(self, size):\n","        in_dim = size[0]\n","        out_dim = size[1]        \n","        xavier_stddev = np.sqrt(2/(in_dim + out_dim))\n","        return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev), dtype=tf.float32)\n","    \n","    def neural_net(self, X, weights, biases, eps=1e-3):\n","        num_layers = len(weights) + 1\n","\n","        H = 2.0*(X - self.lb)/(self.ub - self.lb) - 1.0\n","        for l in range(0,num_layers-2):\n","          W = weights[l]\n","          b = biases[l]\n","          H = tf.nn.relu(tf.add(tf.matmul(H, W), b))\n","        W = weights[-1]\n","        b = biases[-1]\n","        Y = tf.add(tf.matmul(H, W), b)\n","        \n","        \n","            # W = tf.Variable(weights[l])\n","            # b = tf.Variable(biases[l])\n","\n","            # z = tf.matmul(H, W)\n","            # batch_mean, batch_var = tf.nn.moments(z,[0])\n","            # ipdb.set_trace()\n","            # scale = tf.Variable(tf.ones([100]))\n","            # beta = tf.Variable(tf.zeros([100]))\n","            # z_hat = tf.nn.batch_normalization(z,batch_mean,batch_var,beta,scale,eps)\n","            # z = (z - batch_mean) / tf.sqrt(batch_var + eps) # eps = 1e^-3\n","            # H = tf.tanh(tf.add(tf.matmul(z, W), b))\n","            # H = tf.nn.relu(tf.add(tf.matmul(z_hat, W), b))\n","        #     H = tf.nn.relu(tf.add(z, b))\n","        # W = weights[-1]\n","        # b = biases[-1]\n","        # Y = tf.add(tf.matmul(H, W), b)\n","        return Y\n","            \n","    def net_u(self,x,y,t):  \n","        u = self.neural_net(tf.concat([x,y,t],1), self.weights, self.biases)\n","        return u\n","    \n","    def net_f(self, x,y,t):\n","        alpha_1 = self.alpha_1        \n","        u = self.net_u(x,y,t)\n","        u_t = tf.gradients(u, t)[0]\n","        u_x = tf.gradients(u, x)[0]\n","        u_y = tf.gradients(u, y)[0]\n","        u_xx = tf.gradients(u_x, x)[0]\n","        u_yy = tf.gradients(u_y, y)[0]\n","        f = u_t - alpha_1*(u_xx + u_yy)\n","        return f\n","    \n","    def callback(self, self.loss, self.alpha_1):\n","        print('Loss: %e, l1: %.5f' % (self.loss,  self.alpha_1))\n","        \n","        \n","    def train(self, nIter):\n","        tf_dict = {self.x_tf: self.x,self.y_tf: self.y, self.t_tf: self.t, self.u_tf: self.u}\n","        \n","        pinn_df = open('/content/drive/MyDrive/Colab Notebooks/UTRGV-Colab/PINN_output.txt', 'w')\n","\n","        start_time = time.time()\n","        for it in range(nIter):\n","            self.sess.run(self.train_op_Adam, tf_dict)\n","            \n","            # Print            \n","            if it % 10 == 0:\n","                elapsed = time.time() - start_time\n","                loss_value = self.sess.run(self.loss, tf_dict)\n","                alpha_1_value = self.sess.run(self.alpha_1)\n","                #lambda_2_value = np.exp(self.sess.run(self.lambda_2))\n","                \n","                print('It: %d, Loss: %.3e, alpha_1: %.3f, Time: %.2f' % \n","                      (it, loss_value, alpha_1_value, elapsed))\n","                \n","                pinn_df.write('It: %d, Loss: %.3e, alpha_1: %.3f, Time: %.2f \\n' % \n","                      (it, loss_value, alpha_1_value, elapsed))\n","                \n","                start_time = time.time()\n","        \n","        pinn_df.close()\n","        \n","        self.optimizer.minimize(self.sess,\n","                                feed_dict = tf_dict,\n","                                fetches = [self.loss, self.alpha_1],\n","                                loss_callback = self.callback)\n","        \n","        \n","    def predict(self, X_star):\n","        \n","        tf_dict = {self.x_tf: X_star[:,0:1],self.y_tf: X_star[:,1:2], self.t_tf: X_star[:,2:3]}\n","        \n","        u_star = self.sess.run(self.u_pred, tf_dict)\n","        f_star = self.sess.run(self.f_pred, tf_dict)\n","        \n","        return u_star, f_star"],"metadata":{"id":"oPGMZyaPzK_2","executionInfo":{"status":"ok","timestamp":1646529778404,"user_tz":420,"elapsed":260,"user":{"displayName":"Albert Romero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjxCAAyS0BN5ZLXCI4Yl-md_NQNECK-67_AEebWMw=s64","userId":"15395578801537283548"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["#if __name__ == \"__main__\": \n","     \n","    #nu = 0.01/np.pi\n","\n","N_u = 1000000# 853000\n","layers = [3, 20, 20, 20, 20, 20, 20, 20, 20, 1]\n","    \n","    # data = scipy.io.loadmat('../Data/heat_eq.mat')\n","    \n","    #t = data['t'].flatten()[:,None]\n","    #x = data['x'].flatten()[:,None]\n","   # Exact = np.real(data['usol']).T\n","    \n","    #X, T = np.meshgrid(x,t)\n","    \n","input = np.load('/content/drive/MyDrive/Colab Notebooks/UTRGV-Colab/input.npy') # X1, X2 and T as three columns\n","output = np.load('/content/drive/MyDrive/Colab Notebooks/UTRGV-Colab/output.npy') # This is the solution of 2-D heat equation\n","output = output.reshape(output.shape[0],1) # changes shape from (n, ) to (n, 1)\n","    \n","X_star = input #input is coming from the 2Dheat.py file\n","u_star = output.flatten()[:,None] #output is coming from the 2Dheat.py file \n","\n","# Domain bounds\n","lb = input.min(0)\n","ub = input.max(0)\n","\n","print(lb)\n","print(ub)"],"metadata":{"id":"EJDkfU02zH1M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646529783067,"user_tz":420,"elapsed":557,"user":{"displayName":"Albert Romero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjxCAAyS0BN5ZLXCI4Yl-md_NQNECK-67_AEebWMw=s64","userId":"15395578801537283548"}},"outputId":"e1b452f4-1112-4250-c3e0-3df9f17ac3e4"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["[0. 0. 0.]\n","[1.         1.         0.12492188]\n"]}]},{"cell_type":"code","source":["start_point = 1600\n","stop_point = 1844799\n","sa = np.linspace(start_point, stop_point, stop_point-start_point)\n","# t=0 values are preseved in the original dataset as they are intial conditions\n","idx_sample = np.random.choice(sa, N_u, replace=False)\n","\n","# New train Data for 2-D Heat Equation\n","X_u_train = np.vstack((input[0:1600, :], input[idx_sample.astype(int), :]))\n","u_train = np.concatenate([output[0:1600], output[idx_sample.astype(int)]])\n","\n","print(X_u_train.min(0))\n","print(X_u_train.max(0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-O7V5e_J0f3S","executionInfo":{"status":"ok","timestamp":1646529786662,"user_tz":420,"elapsed":544,"user":{"displayName":"Albert Romero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjxCAAyS0BN5ZLXCI4Yl-md_NQNECK-67_AEebWMw=s64","userId":"15395578801537283548"}},"outputId":"72536582-8314-4e7c-a0b0-66d0aaa63581"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["[0. 0. 0.]\n","[1.   1.   0.09]\n"]}]},{"cell_type":"code","source":["######################################################################\n","######################## Noiseless Data ##############################\n","######################################################################\n","noise = 0.0            \n","         \n","# idx = np.random.choice(input.shape[0], N_u, replace=False)\n","# X_u_train = input[idx,:]\n","# u_train = u_star[idx,:]\n","\n","# np.where(input[:,2] >= 0.09)\n","\n","start_point = 1600\n","stop_point = 1844799\n","sa = np.linspace(start_point, stop_point, stop_point-start_point)\n","# t=0 values are preseved in the original dataset as they are intial conditions\n","idx_sample = np.random.choice(sa, N_u, replace=False)\n","\n","# New train Data for 2-D Heat Equation\n","X_u_train = np.vstack((input[0:1600, :], input[idx_sample.astype(int), :]))\n","u_train = np.concatenate([output[0:1600], output[idx_sample.astype(int)]])\n","\n","# X_u_train = input[:1844800, :]\n","# u_train = output[:1844800]\n","\n","model = PhysicsInformedNN(X_u_train, u_train, layers, lb, ub)\n","model.train(10000)#You can run for small iterations first, to see whether it is running properly\n","\n","u_pred, f_pred = model.predict(X_star)\n","        \n","error_u = np.linalg.norm(u_star-u_pred,2)/np.linalg.norm(u_star,2)\n","\n","#\\U_pred = griddata(X_star, u_pred.flatten(), (X, T), method='cubic')#This graphing part yet to be figure out.\n","    \n","alpha_1_value = model.sess.run(model.alpha_1)\n","#lambda_2_value = model.sess.run(model.lambda_2)\n","#lambda_2_value = np.exp(lambda_2_value)\n","\n","error_alpha_1 = np.abs(alpha_1_value - 2)*100\n","#error_lambda_2 = np.abs(lambda_2_value - nu)/nu * 100\n","\n","\n","print('Error u: %e' % (error_u))    \n","print('Error l1: %.5f%%' % (error_alpha_1)) \n","\n","df = open('output.txt', 'w')\n","df.write('Error u: %e' % (error_u))  \n","df.write('\\n')\n","df.close()\n","\n","np.save('/content/drive/MyDrive/Colab Notebooks/UTRGV-Colab//u_train-18Feb2022-relu-2.npy', u_train)\n","\n","u_pred_3D = np.reshape(u_pred, (1600, 40, 40))\n","np.save('/content/drive/MyDrive/Colab Notebooks/UTRGV-Colab/u_pred_3D-18Feb2022-relu-2.npy', u_pred_3D)"],"metadata":{"id":"yPvl7r_f0F1W","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e7b3df75-fd55-4fd4-b3f5-225b8cb8607d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","It: 0, Loss: 1.175e+03, alpha_1: -1.800, Time: 1.68\n","It: 10, Loss: 1.108e+03, alpha_1: -1.800, Time: 3.81\n","It: 20, Loss: 7.131e+02, alpha_1: -1.800, Time: 3.81\n","It: 30, Loss: 4.959e+02, alpha_1: -1.800, Time: 3.80\n","It: 40, Loss: 2.737e+02, alpha_1: -1.800, Time: 3.80\n","It: 50, Loss: 1.477e+02, alpha_1: -1.800, Time: 3.81\n","It: 60, Loss: 1.249e+02, alpha_1: -1.800, Time: 3.80\n","It: 70, Loss: 1.117e+02, alpha_1: -1.800, Time: 3.80\n","It: 80, Loss: 1.034e+02, alpha_1: -1.800, Time: 3.81\n","It: 90, Loss: 9.790e+01, alpha_1: -1.800, Time: 3.80\n","It: 100, Loss: 9.175e+01, alpha_1: -1.800, Time: 3.81\n","It: 110, Loss: 8.541e+01, alpha_1: -1.800, Time: 3.82\n","It: 120, Loss: 7.953e+01, alpha_1: -1.800, Time: 3.80\n","It: 130, Loss: 7.271e+01, alpha_1: -1.800, Time: 3.80\n","It: 140, Loss: 7.077e+01, alpha_1: -1.800, Time: 3.80\n","It: 150, Loss: 6.508e+01, alpha_1: -1.800, Time: 3.80\n","It: 160, Loss: 6.317e+01, alpha_1: -1.800, Time: 3.80\n","It: 170, Loss: 6.271e+01, alpha_1: -1.800, Time: 3.80\n","It: 180, Loss: 6.070e+01, alpha_1: -1.800, Time: 3.80\n","It: 190, Loss: 5.751e+01, alpha_1: -1.800, Time: 3.80\n","It: 200, Loss: 6.163e+01, alpha_1: -1.800, Time: 3.80\n","It: 210, Loss: 6.329e+01, alpha_1: -1.800, Time: 3.80\n","It: 220, Loss: 6.136e+01, alpha_1: -1.800, Time: 3.80\n","It: 230, Loss: 5.682e+01, alpha_1: -1.800, Time: 3.80\n","It: 240, Loss: 5.377e+01, alpha_1: -1.800, Time: 3.80\n","It: 250, Loss: 5.273e+01, alpha_1: -1.800, Time: 3.80\n","It: 260, Loss: 5.145e+01, alpha_1: -1.800, Time: 3.80\n","It: 270, Loss: 5.084e+01, alpha_1: -1.800, Time: 3.80\n","It: 280, Loss: 5.063e+01, alpha_1: -1.800, Time: 3.80\n","It: 290, Loss: 5.051e+01, alpha_1: -1.800, Time: 3.80\n","It: 300, Loss: 4.919e+01, alpha_1: -1.800, Time: 3.80\n","It: 310, Loss: 4.955e+01, alpha_1: -1.800, Time: 3.80\n","It: 320, Loss: 4.842e+01, alpha_1: -1.800, Time: 3.80\n","It: 330, Loss: 4.804e+01, alpha_1: -1.800, Time: 3.80\n","It: 340, Loss: 4.820e+01, alpha_1: -1.800, Time: 3.80\n","It: 350, Loss: 5.807e+01, alpha_1: -1.800, Time: 3.80\n","It: 360, Loss: 5.090e+01, alpha_1: -1.800, Time: 3.79\n","It: 370, Loss: 4.774e+01, alpha_1: -1.800, Time: 3.80\n","It: 380, Loss: 4.761e+01, alpha_1: -1.800, Time: 3.80\n","It: 390, Loss: 4.818e+01, alpha_1: -1.800, Time: 3.80\n","It: 400, Loss: 4.820e+01, alpha_1: -1.800, Time: 3.80\n","It: 410, Loss: 4.754e+01, alpha_1: -1.800, Time: 3.80\n","It: 420, Loss: 4.782e+01, alpha_1: -1.800, Time: 3.80\n","It: 430, Loss: 4.800e+01, alpha_1: -1.800, Time: 3.80\n","It: 440, Loss: 4.847e+01, alpha_1: -1.800, Time: 3.80\n","It: 450, Loss: 4.856e+01, alpha_1: -1.800, Time: 3.80\n","It: 460, Loss: 4.806e+01, alpha_1: -1.800, Time: 3.80\n","It: 470, Loss: 4.773e+01, alpha_1: -1.800, Time: 3.80\n","It: 480, Loss: 4.659e+01, alpha_1: -1.800, Time: 3.80\n","It: 490, Loss: 4.628e+01, alpha_1: -1.800, Time: 3.80\n","It: 500, Loss: 4.714e+01, alpha_1: -1.800, Time: 3.79\n","It: 510, Loss: 5.647e+01, alpha_1: -1.800, Time: 3.80\n","It: 520, Loss: 5.187e+01, alpha_1: -1.800, Time: 3.79\n","It: 530, Loss: 4.673e+01, alpha_1: -1.800, Time: 3.80\n","It: 540, Loss: 4.660e+01, alpha_1: -1.800, Time: 3.80\n","It: 550, Loss: 4.630e+01, alpha_1: -1.800, Time: 3.80\n","It: 560, Loss: 4.614e+01, alpha_1: -1.800, Time: 3.80\n","It: 570, Loss: 4.564e+01, alpha_1: -1.800, Time: 3.80\n","It: 580, Loss: 5.387e+01, alpha_1: -1.800, Time: 3.79\n","It: 590, Loss: 4.868e+01, alpha_1: -1.800, Time: 3.80\n","It: 600, Loss: 4.659e+01, alpha_1: -1.800, Time: 3.81\n","It: 610, Loss: 4.612e+01, alpha_1: -1.800, Time: 3.80\n","It: 620, Loss: 4.588e+01, alpha_1: -1.800, Time: 3.80\n","It: 630, Loss: 4.568e+01, alpha_1: -1.800, Time: 3.82\n","It: 640, Loss: 4.552e+01, alpha_1: -1.800, Time: 3.87\n","It: 650, Loss: 4.718e+01, alpha_1: -1.800, Time: 3.85\n","It: 660, Loss: 4.810e+01, alpha_1: -1.800, Time: 3.82\n","It: 670, Loss: 4.585e+01, alpha_1: -1.800, Time: 3.79\n","It: 680, Loss: 4.526e+01, alpha_1: -1.800, Time: 3.80\n","It: 690, Loss: 4.688e+01, alpha_1: -1.800, Time: 3.80\n","It: 700, Loss: 5.026e+01, alpha_1: -1.800, Time: 3.79\n","It: 710, Loss: 4.589e+01, alpha_1: -1.800, Time: 3.80\n","It: 720, Loss: 4.636e+01, alpha_1: -1.800, Time: 3.80\n","It: 730, Loss: 4.504e+01, alpha_1: -1.800, Time: 3.80\n","It: 740, Loss: 4.526e+01, alpha_1: -1.800, Time: 3.80\n","It: 750, Loss: 4.567e+01, alpha_1: -1.800, Time: 3.80\n","It: 760, Loss: 4.490e+01, alpha_1: -1.800, Time: 3.80\n","It: 770, Loss: 1.366e+02, alpha_1: -1.800, Time: 3.80\n","It: 780, Loss: 1.631e+02, alpha_1: -1.800, Time: 3.80\n","It: 790, Loss: 1.080e+02, alpha_1: -1.800, Time: 3.80\n","It: 800, Loss: 8.209e+01, alpha_1: -1.800, Time: 3.80\n","It: 810, Loss: 7.739e+01, alpha_1: -1.800, Time: 3.80\n","It: 820, Loss: 7.395e+01, alpha_1: -1.800, Time: 3.79\n","It: 830, Loss: 6.985e+01, alpha_1: -1.800, Time: 3.79\n","It: 840, Loss: 6.631e+01, alpha_1: -1.800, Time: 3.80\n","It: 850, Loss: 6.356e+01, alpha_1: -1.800, Time: 3.80\n","It: 860, Loss: 6.123e+01, alpha_1: -1.800, Time: 3.80\n","It: 870, Loss: 5.912e+01, alpha_1: -1.800, Time: 3.79\n","It: 880, Loss: 5.722e+01, alpha_1: -1.800, Time: 3.80\n","It: 890, Loss: 5.555e+01, alpha_1: -1.800, Time: 3.79\n","It: 900, Loss: 5.349e+01, alpha_1: -1.800, Time: 3.79\n","It: 910, Loss: 5.180e+01, alpha_1: -1.800, Time: 3.79\n","It: 920, Loss: 5.042e+01, alpha_1: -1.800, Time: 3.80\n","It: 930, Loss: 4.956e+01, alpha_1: -1.800, Time: 3.84\n","It: 940, Loss: 4.861e+01, alpha_1: -1.800, Time: 3.80\n","It: 950, Loss: 5.837e+01, alpha_1: -1.800, Time: 3.79\n","It: 960, Loss: 5.371e+01, alpha_1: -1.800, Time: 3.80\n","It: 970, Loss: 5.068e+01, alpha_1: -1.800, Time: 3.79\n","It: 980, Loss: 4.901e+01, alpha_1: -1.800, Time: 3.80\n","It: 990, Loss: 4.807e+01, alpha_1: -1.800, Time: 3.80\n","It: 1000, Loss: 4.744e+01, alpha_1: -1.800, Time: 3.88\n","It: 1010, Loss: 4.702e+01, alpha_1: -1.800, Time: 3.84\n","It: 1020, Loss: 4.672e+01, alpha_1: -1.800, Time: 3.82\n","It: 1030, Loss: 4.651e+01, alpha_1: -1.800, Time: 3.84\n","It: 1040, Loss: 4.632e+01, alpha_1: -1.800, Time: 3.83\n","It: 1050, Loss: 4.639e+01, alpha_1: -1.800, Time: 3.83\n","It: 1060, Loss: 4.626e+01, alpha_1: -1.800, Time: 3.83\n","It: 1070, Loss: 4.589e+01, alpha_1: -1.800, Time: 3.80\n","It: 1080, Loss: 4.579e+01, alpha_1: -1.800, Time: 3.79\n","It: 1090, Loss: 4.566e+01, alpha_1: -1.800, Time: 3.80\n","It: 1100, Loss: 4.553e+01, alpha_1: -1.800, Time: 3.80\n","It: 1110, Loss: 4.543e+01, alpha_1: -1.800, Time: 3.80\n","It: 1120, Loss: 4.531e+01, alpha_1: -1.800, Time: 3.80\n","It: 1130, Loss: 4.525e+01, alpha_1: -1.800, Time: 3.80\n","It: 1140, Loss: 4.520e+01, alpha_1: -1.800, Time: 3.80\n","It: 1150, Loss: 4.517e+01, alpha_1: -1.800, Time: 3.79\n","It: 1160, Loss: 4.531e+01, alpha_1: -1.800, Time: 3.79\n","It: 1170, Loss: 4.489e+01, alpha_1: -1.800, Time: 3.79\n","It: 1180, Loss: 4.478e+01, alpha_1: -1.800, Time: 3.79\n","It: 1190, Loss: 4.467e+01, alpha_1: -1.800, Time: 3.79\n","It: 1200, Loss: 4.460e+01, alpha_1: -1.800, Time: 3.79\n","It: 1210, Loss: 4.455e+01, alpha_1: -1.800, Time: 3.80\n","It: 1220, Loss: 4.534e+01, alpha_1: -1.800, Time: 3.80\n","It: 1230, Loss: 4.460e+01, alpha_1: -1.800, Time: 3.79\n","It: 1240, Loss: 4.457e+01, alpha_1: -1.800, Time: 3.80\n","It: 1250, Loss: 4.419e+01, alpha_1: -1.800, Time: 3.80\n","It: 1260, Loss: 4.413e+01, alpha_1: -1.800, Time: 3.80\n","It: 1270, Loss: 4.405e+01, alpha_1: -1.800, Time: 3.79\n","It: 1280, Loss: 4.400e+01, alpha_1: -1.800, Time: 3.80\n","It: 1290, Loss: 4.496e+01, alpha_1: -1.800, Time: 3.80\n","It: 1300, Loss: 4.428e+01, alpha_1: -1.800, Time: 3.79\n","It: 1310, Loss: 4.400e+01, alpha_1: -1.800, Time: 3.79\n","It: 1320, Loss: 4.408e+01, alpha_1: -1.800, Time: 3.79\n","It: 1330, Loss: 4.388e+01, alpha_1: -1.800, Time: 3.79\n","It: 1340, Loss: 4.393e+01, alpha_1: -1.800, Time: 3.79\n","It: 1350, Loss: 4.391e+01, alpha_1: -1.800, Time: 3.80\n","It: 1360, Loss: 4.387e+01, alpha_1: -1.800, Time: 3.79\n","It: 1370, Loss: 4.383e+01, alpha_1: -1.800, Time: 3.80\n","It: 1380, Loss: 4.372e+01, alpha_1: -1.800, Time: 3.79\n","It: 1390, Loss: 4.407e+01, alpha_1: -1.800, Time: 3.79\n","It: 1400, Loss: 4.374e+01, alpha_1: -1.800, Time: 3.79\n","It: 1410, Loss: 4.367e+01, alpha_1: -1.800, Time: 3.79\n","It: 1420, Loss: 4.362e+01, alpha_1: -1.800, Time: 3.80\n","It: 1430, Loss: 4.372e+01, alpha_1: -1.800, Time: 3.79\n","It: 1440, Loss: 4.358e+01, alpha_1: -1.800, Time: 3.82\n","It: 1450, Loss: 4.383e+01, alpha_1: -1.800, Time: 3.84\n","It: 1460, Loss: 4.455e+01, alpha_1: -1.800, Time: 3.81\n","It: 1470, Loss: 4.396e+01, alpha_1: -1.800, Time: 3.80\n","It: 1480, Loss: 4.371e+01, alpha_1: -1.800, Time: 3.79\n","It: 1490, Loss: 4.356e+01, alpha_1: -1.800, Time: 3.79\n","It: 1500, Loss: 4.353e+01, alpha_1: -1.800, Time: 3.79\n","It: 1510, Loss: 4.359e+01, alpha_1: -1.800, Time: 3.80\n","It: 1520, Loss: 4.350e+01, alpha_1: -1.800, Time: 3.79\n","It: 1530, Loss: 4.348e+01, alpha_1: -1.800, Time: 3.79\n","It: 1540, Loss: 4.344e+01, alpha_1: -1.800, Time: 3.79\n","It: 1550, Loss: 4.351e+01, alpha_1: -1.800, Time: 3.80\n","It: 1560, Loss: 4.362e+01, alpha_1: -1.800, Time: 3.80\n","It: 1570, Loss: 4.411e+01, alpha_1: -1.800, Time: 3.80\n","It: 1580, Loss: 7.766e+01, alpha_1: -1.800, Time: 3.79\n","It: 1590, Loss: 6.042e+01, alpha_1: -1.800, Time: 3.79\n","It: 1600, Loss: 6.705e+01, alpha_1: -1.800, Time: 3.79\n","It: 1610, Loss: 6.112e+01, alpha_1: -1.800, Time: 3.79\n","It: 1620, Loss: 5.652e+01, alpha_1: -1.800, Time: 3.79\n","It: 1630, Loss: 5.411e+01, alpha_1: -1.800, Time: 3.79\n","It: 1640, Loss: 5.234e+01, alpha_1: -1.800, Time: 3.79\n","It: 1650, Loss: 5.121e+01, alpha_1: -1.800, Time: 3.79\n","It: 1660, Loss: 5.041e+01, alpha_1: -1.800, Time: 3.79\n","It: 1670, Loss: 4.974e+01, alpha_1: -1.800, Time: 3.79\n","It: 1680, Loss: 4.919e+01, alpha_1: -1.800, Time: 3.79\n","It: 1690, Loss: 4.865e+01, alpha_1: -1.800, Time: 3.80\n","It: 1700, Loss: 4.815e+01, alpha_1: -1.800, Time: 3.79\n","It: 1710, Loss: 4.762e+01, alpha_1: -1.800, Time: 3.80\n","It: 1720, Loss: 4.723e+01, alpha_1: -1.800, Time: 3.79\n","It: 1730, Loss: 4.687e+01, alpha_1: -1.800, Time: 3.79\n","It: 1740, Loss: 4.653e+01, alpha_1: -1.800, Time: 3.81\n","It: 1750, Loss: 4.628e+01, alpha_1: -1.800, Time: 3.80\n","It: 1760, Loss: 5.468e+01, alpha_1: -1.800, Time: 3.79\n","It: 1770, Loss: 4.883e+01, alpha_1: -1.800, Time: 3.79\n","It: 1780, Loss: 4.643e+01, alpha_1: -1.800, Time: 3.80\n","It: 1790, Loss: 4.571e+01, alpha_1: -1.800, Time: 3.80\n","It: 1800, Loss: 4.507e+01, alpha_1: -1.800, Time: 3.80\n","It: 1810, Loss: 4.484e+01, alpha_1: -1.800, Time: 3.79\n","It: 1820, Loss: 4.466e+01, alpha_1: -1.800, Time: 3.80\n","It: 1830, Loss: 4.450e+01, alpha_1: -1.800, Time: 3.80\n","It: 1840, Loss: 5.084e+01, alpha_1: -1.800, Time: 3.79\n","It: 1850, Loss: 4.586e+01, alpha_1: -1.800, Time: 3.80\n","It: 1860, Loss: 4.454e+01, alpha_1: -1.800, Time: 3.80\n","It: 1870, Loss: 4.442e+01, alpha_1: -1.800, Time: 3.79\n","It: 1880, Loss: 4.429e+01, alpha_1: -1.800, Time: 3.79\n","It: 1890, Loss: 4.412e+01, alpha_1: -1.800, Time: 3.80\n","It: 1900, Loss: 4.408e+01, alpha_1: -1.800, Time: 3.80\n","It: 1910, Loss: 4.400e+01, alpha_1: -1.800, Time: 3.80\n","It: 1920, Loss: 4.396e+01, alpha_1: -1.800, Time: 3.79\n","It: 1930, Loss: 4.394e+01, alpha_1: -1.800, Time: 3.79\n","It: 1940, Loss: 4.400e+01, alpha_1: -1.800, Time: 3.80\n","It: 1950, Loss: 4.621e+01, alpha_1: -1.800, Time: 3.79\n","It: 1960, Loss: 4.445e+01, alpha_1: -1.800, Time: 3.79\n","It: 1970, Loss: 4.390e+01, alpha_1: -1.800, Time: 3.79\n","It: 1980, Loss: 4.396e+01, alpha_1: -1.800, Time: 3.79\n","It: 1990, Loss: 4.388e+01, alpha_1: -1.800, Time: 3.80\n","It: 2000, Loss: 4.380e+01, alpha_1: -1.800, Time: 3.79\n","It: 2010, Loss: 4.381e+01, alpha_1: -1.800, Time: 3.79\n","It: 2020, Loss: 4.414e+01, alpha_1: -1.800, Time: 3.79\n","It: 2030, Loss: 4.470e+01, alpha_1: -1.800, Time: 3.79\n","It: 2040, Loss: 4.380e+01, alpha_1: -1.800, Time: 3.80\n","It: 2050, Loss: 4.375e+01, alpha_1: -1.800, Time: 3.80\n","It: 2060, Loss: 4.371e+01, alpha_1: -1.800, Time: 3.79\n","It: 2070, Loss: 4.371e+01, alpha_1: -1.800, Time: 3.80\n","It: 2080, Loss: 4.388e+01, alpha_1: -1.800, Time: 3.79\n","It: 2090, Loss: 4.780e+01, alpha_1: -1.800, Time: 3.80\n","It: 2100, Loss: 4.421e+01, alpha_1: -1.800, Time: 3.79\n","It: 2110, Loss: 4.397e+01, alpha_1: -1.800, Time: 3.80\n","It: 2120, Loss: 4.377e+01, alpha_1: -1.800, Time: 3.79\n","It: 2130, Loss: 4.366e+01, alpha_1: -1.800, Time: 3.79\n","It: 2140, Loss: 4.363e+01, alpha_1: -1.800, Time: 3.79\n","It: 2150, Loss: 4.356e+01, alpha_1: -1.800, Time: 3.79\n","It: 2160, Loss: 4.353e+01, alpha_1: -1.800, Time: 3.79\n","It: 2170, Loss: 4.353e+01, alpha_1: -1.800, Time: 3.80\n","It: 2180, Loss: 4.353e+01, alpha_1: -1.800, Time: 3.79\n","It: 2190, Loss: 4.363e+01, alpha_1: -1.800, Time: 3.80\n","It: 2200, Loss: 4.349e+01, alpha_1: -1.800, Time: 3.79\n","It: 2210, Loss: 4.352e+01, alpha_1: -1.800, Time: 3.79\n","It: 2220, Loss: 4.347e+01, alpha_1: -1.800, Time: 3.79\n","It: 2230, Loss: 4.345e+01, alpha_1: -1.800, Time: 3.79\n","It: 2240, Loss: 4.347e+01, alpha_1: -1.800, Time: 3.79\n","It: 2250, Loss: 4.349e+01, alpha_1: -1.800, Time: 3.80\n","It: 2260, Loss: 4.357e+01, alpha_1: -1.800, Time: 3.80\n","It: 2270, Loss: 4.364e+01, alpha_1: -1.800, Time: 3.80\n","It: 2280, Loss: 4.367e+01, alpha_1: -1.800, Time: 3.79\n","It: 2290, Loss: 4.370e+01, alpha_1: -1.800, Time: 3.79\n","It: 2300, Loss: 4.358e+01, alpha_1: -1.800, Time: 3.79\n","It: 2310, Loss: 4.361e+01, alpha_1: -1.800, Time: 3.79\n","It: 2320, Loss: 4.345e+01, alpha_1: -1.800, Time: 3.80\n","It: 2330, Loss: 4.363e+01, alpha_1: -1.800, Time: 3.80\n","It: 2340, Loss: 4.360e+01, alpha_1: -1.800, Time: 3.79\n","It: 2350, Loss: 4.349e+01, alpha_1: -1.800, Time: 3.79\n","It: 2360, Loss: 4.340e+01, alpha_1: -1.800, Time: 3.79\n","It: 2370, Loss: 4.415e+01, alpha_1: -1.800, Time: 3.79\n","It: 2380, Loss: 4.344e+01, alpha_1: -1.800, Time: 3.79\n","It: 2390, Loss: 4.367e+01, alpha_1: -1.800, Time: 3.79\n","It: 2400, Loss: 4.364e+01, alpha_1: -1.800, Time: 3.79\n","It: 2410, Loss: 4.346e+01, alpha_1: -1.800, Time: 3.79\n","It: 2420, Loss: 4.342e+01, alpha_1: -1.800, Time: 3.80\n","It: 2430, Loss: 4.338e+01, alpha_1: -1.800, Time: 3.79\n","It: 2440, Loss: 4.337e+01, alpha_1: -1.800, Time: 3.79\n","It: 2450, Loss: 4.337e+01, alpha_1: -1.800, Time: 3.79\n","It: 2460, Loss: 4.336e+01, alpha_1: -1.800, Time: 3.79\n","It: 2470, Loss: 4.336e+01, alpha_1: -1.800, Time: 3.79\n","It: 2480, Loss: 4.338e+01, alpha_1: -1.800, Time: 3.79\n","It: 2490, Loss: 4.336e+01, alpha_1: -1.800, Time: 3.79\n","It: 2500, Loss: 4.337e+01, alpha_1: -1.800, Time: 3.79\n","It: 2510, Loss: 4.338e+01, alpha_1: -1.800, Time: 3.79\n","It: 2520, Loss: 4.334e+01, alpha_1: -1.800, Time: 3.79\n","It: 2530, Loss: 4.334e+01, alpha_1: -1.800, Time: 3.79\n","It: 2540, Loss: 4.342e+01, alpha_1: -1.800, Time: 3.79\n","It: 2550, Loss: 4.336e+01, alpha_1: -1.800, Time: 3.79\n","It: 2560, Loss: 4.337e+01, alpha_1: -1.800, Time: 3.80\n","It: 2570, Loss: 4.368e+01, alpha_1: -1.800, Time: 3.79\n","It: 2580, Loss: 4.344e+01, alpha_1: -1.800, Time: 3.79\n","It: 2590, Loss: 4.337e+01, alpha_1: -1.800, Time: 3.79\n","It: 2600, Loss: 4.364e+01, alpha_1: -1.800, Time: 3.79\n","It: 2610, Loss: 4.357e+01, alpha_1: -1.800, Time: 3.79\n","It: 2620, Loss: 4.338e+01, alpha_1: -1.800, Time: 3.79\n","It: 2630, Loss: 4.481e+01, alpha_1: -1.800, Time: 3.80\n","It: 2640, Loss: 4.543e+01, alpha_1: -1.800, Time: 3.79\n","It: 2650, Loss: 4.437e+01, alpha_1: -1.800, Time: 3.80\n","It: 2660, Loss: 4.459e+01, alpha_1: -1.800, Time: 3.79\n","It: 2670, Loss: 4.368e+01, alpha_1: -1.800, Time: 3.80\n","It: 2680, Loss: 4.365e+01, alpha_1: -1.800, Time: 3.79\n","It: 2690, Loss: 4.348e+01, alpha_1: -1.800, Time: 3.80\n","It: 2700, Loss: 4.342e+01, alpha_1: -1.800, Time: 3.79\n","It: 2710, Loss: 4.337e+01, alpha_1: -1.800, Time: 3.79\n","It: 2720, Loss: 4.336e+01, alpha_1: -1.800, Time: 3.79\n","It: 2730, Loss: 4.335e+01, alpha_1: -1.800, Time: 3.79\n","It: 2740, Loss: 4.335e+01, alpha_1: -1.800, Time: 3.79\n","It: 2750, Loss: 4.335e+01, alpha_1: -1.800, Time: 3.79\n","It: 2760, Loss: 4.334e+01, alpha_1: -1.800, Time: 3.79\n","It: 2770, Loss: 4.335e+01, alpha_1: -1.800, Time: 3.80\n","It: 2780, Loss: 4.334e+01, alpha_1: -1.800, Time: 3.79\n","It: 2790, Loss: 4.334e+01, alpha_1: -1.800, Time: 3.80\n","It: 2800, Loss: 4.335e+01, alpha_1: -1.800, Time: 3.79\n","It: 2810, Loss: 4.807e+01, alpha_1: -1.800, Time: 3.79\n","It: 2820, Loss: 4.432e+01, alpha_1: -1.800, Time: 3.79\n","It: 2830, Loss: 4.410e+01, alpha_1: -1.800, Time: 3.79\n","It: 2840, Loss: 4.351e+01, alpha_1: -1.800, Time: 3.79\n","It: 2850, Loss: 4.341e+01, alpha_1: -1.800, Time: 3.79\n"]}]},{"cell_type":"code","source":["%debug"],"metadata":{"id":"E6VMyJuTknGL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(u_pred)"],"metadata":{"id":"NK2wXMepw1F6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.reshape(u_pred, (1600,40,40))[0, :, :]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":165},"id":"H4m3wc5b4Qp2","executionInfo":{"status":"error","timestamp":1645816528602,"user_tz":420,"elapsed":6,"user":{"displayName":"Albert Romero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjxCAAyS0BN5ZLXCI4Yl-md_NQNECK-67_AEebWMw=s64","userId":"15395578801537283548"}},"outputId":"875d9307-1e74-4b22-c151-a33cf1818ea3"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-3072ea41b5e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1600\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"]}]},{"cell_type":"code","source":["print(X_u_train)"],"metadata":{"id":"WA_ppsNsvgaN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(u_train)\n","np.save('/content/drive/MyDrive/Colab Notebooks/UTRGV-Colab//u_train-12Feb2022.npy', u_train)"],"metadata":{"id":"WhS9a9C6vjmS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["u_pred_3D = np.reshape(u_pred, (1600, 40, 40))\n","np.save('/content/drive/MyDrive/Colab Notebooks/UTRGV-Colab/u_pred_3D-12Feb2022.npy', u_pred_3D)"],"metadata":{"id":"bTNX57c-GDea"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(u_pred_3D)"],"metadata":{"id":"hu0O_YUDTzGe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["######################################################################\n","############################ Animation ###############################\n","###################################################################### \n","import matplotlib\n","from matplotlib import rc\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","rc('text', usetex=True)\n","matplotlib.rcParams['text.latex.preamble'] = [r'\\usepackage{amsmath}']\n","!apt install texlive-fonts-recommended texlive-fonts-extra cm-super dvipng\n","\n","u_pred_3D = np.reshape(u_pred, (1600, 40, 40))\n","\n","plate_length = 1  # 10\n","delta_x = 0.025\n","\n","alpha = 2\n","\n","num_x_inter = int((plate_length)/delta_x)\n","max_iter_time = num_x_inter * num_x_inter\n","\n","delta_t = (delta_x ** 2)/(4 * alpha)\n","gamma = (alpha * delta_t) / (delta_x ** 2)\n","\n","tick_intervals = np.linspace(0, 40, 11, retstep=True)[0]\n","tick_labels = np.array(\n","['0.0', '0.1', '0.2', '0.3', '0.4', '0.5', '0.6', '0.7', '0.8', '0.9', '1.0'])\n","\n","\n","def plotheatmap(u_k, k):\n","  # Clear the current plot figure\n","  plt.clf()\n","\n","  plt.title(f\"Temperature at t = {k*delta_t:.3f} unit time\")\n","\n","  plt.xlabel(\"x\")\n","  plt.xticks(tick_intervals, tick_labels)\n","\n","  plt.ylabel(\"y\")\n","  plt.yticks(tick_intervals, tick_labels)\n","\n","        # This is to plot u_k (u at time-step k)\n","  plt.pcolormesh(u_k, cmap=plt.cm.jet, vmin=0, vmax=100)\n","  plt.colorbar()\n","\n","  return plt\n","\n","\n","def animate(k):\n","  plotheatmap(u_pred_3D[k], k)\n","\n","\n","anim = animation.FuncAnimation(\n","    plt.figure(), animate, interval=1, frames=max_iter_time, repeat=False)\n","anim.save(\"predicted_heat_equation_solution-07Feb2022.gif\")"],"metadata":{"id":"1i9X_YJ6xdrt"},"execution_count":null,"outputs":[]}]}